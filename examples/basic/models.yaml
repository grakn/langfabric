# Chat model using GPT-4o
- name: gpt4o-chat
  provider: openai
  model: gpt-4o
  api_key: !env OPENAI_API_KEY
  max_tokens: 4096
  temperature: 0.7
  streaming: true

# Mid-size chat model
- name: gpt4o-mini
  provider: openai
  model: o4-mini
  api_key: !env OPENAI_API_KEY
  max_tokens: 4096
  streaming: True
  verbose: True

# Lightweight chat model
- name: gpt35-turbo
  provider: openai
  model: gpt-3.5-turbo
  api_key: !env OPENAI_API_KEY
  max_tokens: 2048
  temperature: 0.7
  streaming: true

# Self-hosted chat model
- name: gemma3
  provider: ollama
  model: gemma3:12b
  max_tokens: 4096
  streaming: True
  verbose: True
